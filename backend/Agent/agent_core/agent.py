"""
åŸºäºLangChainçš„å…¬å¹³ç«äº‰å®¡æŸ¥Agentæ ¸å¿ƒ
æ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œç»Ÿä¸€é…ç½®ç®¡ç†
"""

import json
import logging
from typing import Dict, List, Any, Optional, Union

# LangChainæ ¸å¿ƒç»„ä»¶
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import BaseTool, StructuredTool
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import LLMChain
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks.manager import CallbackManager

# LangChain LLMç»„ä»¶
from langchain_community.llms import OpenAI
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatTongyi
from langchain.llms.base import BaseLLM

# LangChainå·¥å…·å’Œè®°å¿†
from langchain.tools import Tool
from langchain.memory import ConversationBufferWindowMemory

# è‡ªå®šä¹‰å·¥å…·
from agent_tools.langchain_tools import FairCompetitionRetrievalTool, DocumentAnalysisTool

# ç»Ÿä¸€é…ç½®
from config.settings import get_settings

logger = logging.getLogger(__name__)


class LangChainAgent:
    """åŸºäºLangChainçš„å…¬å¹³ç«äº‰å®¡æŸ¥Agent"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.settings = get_settings()
        self.config = config or self.settings.get_agent_config()
        self.llm_config = self.settings.get_llm_config()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.llm = self._initialize_llm()
        self.tools = self._initialize_tools()
        self.memory = self._initialize_memory()
        self.prompt = self._create_prompt()
        self.agent = self._create_agent()
        self.agent_executor = self._create_agent_executor()

        logger.info(f"LangChain Agentåˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: doubao-seed-1-6-250615")

    def _initialize_llm(self):
        """åˆå§‹åŒ–LLM"""
        try:
            llm_config = {**self.llm_config}
            api_key = llm_config.get("api_key")
            if not api_key:
                raise ValueError("VOLC_ARK_API_KEY æœªé…ç½®ï¼Œæ— æ³•åˆå§‹åŒ–LLM")

            logger.info(
                "LLMé…ç½®: provider=%s model=%s temperature=%s max_tokens=%s",
                llm_config.get("provider"),
                llm_config.get("model"),
                llm_config.get("temperature"),
                llm_config.get("max_tokens"),
            )
            
            if llm_config["provider"] == "volcengine_ark":
                # ä½¿ç”¨ç«å±±å¼•æ“åŸç”ŸAPI
                try:
                    from volcengine.ark import Ark
                    
                    # åˆå§‹åŒ–ç«å±±å¼•æ“ARKå®¢æˆ·ç«¯
                    ark = Ark(
                        api_key=api_key,
                        region="cn-beijing"  # æ ¹æ®ä½ çš„åŒºåŸŸè®¾ç½®
                    )
                    
                    # åˆ›å»ºè‡ªå®šä¹‰çš„LangChainå…¼å®¹ç±»
                    class VolcengineArkLLM(BaseLLM):
                        def __init__(self, ark_client, model_name, **kwargs):
                            super().__init__(**kwargs)
                            self.ark_client = ark_client
                            self.model_name = model_name
                            
                        def _call(self, prompt, stop=None, run_manager=None, **kwargs):
                            try:
                                response = self.ark_client.chat.completions.create(
                                    model=self.model_name,
                                    messages=[{"role": "user", "content": prompt}],
                                    temperature=kwargs.get("temperature", 0.1),
                                    max_tokens=kwargs.get("max_tokens", 2048)
                                )
                                return response.choices[0].message.content
                            except Exception as e:
                                logger.error(f"ç«å±±å¼•æ“APIè°ƒç”¨å¤±è´¥: {e}")
                                raise
                        
                        @property
                        def _llm_type(self):
                            return "volcengine_ark"
                    
                    return VolcengineArkLLM(
                        ark_client=ark,
                        model_name=llm_config["model"],
                        temperature=llm_config["temperature"],
                        max_tokens=llm_config["max_tokens"]
                    )
                    
                except ImportError:
                    logger.error("æœªå®‰è£…volcengine SDKï¼Œè¯·è¿è¡Œ: pip install volcengine")
                    raise
                except Exception as e:
                    logger.error(f"ç«å±±å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
                    raise
            elif llm_config["provider"] == "openai":
                return ChatOpenAI(
                        model=llm_config["model"],
                        api_key=api_key,
                    base_url=llm_config.get("base_url"),
                    temperature=llm_config["temperature"],
                    max_tokens=llm_config["max_tokens"],
                    streaming=True,  # å¯ç”¨æµå¼è¾“å‡º
                    verbose=getattr(self.config, "verbose", True)
                )
            elif llm_config["provider"] == "tongyi":
                return ChatTongyi(
                        model_name=llm_config["model"],
                        api_key=api_key,
                    temperature=llm_config["temperature"],
                    max_tokens=llm_config["max_tokens"],
                    streaming=True  # å¯ç”¨æµå¼è¾“å‡º
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {llm_config['provider']}")

        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise ValueError(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")

    def _initialize_tools(self) -> List[BaseTool]:
        """åˆå§‹åŒ–å·¥å…·"""
        try:
            tools = []
            
            # å…¬å¹³ç«äº‰å®¡æŸ¥æ£€ç´¢å·¥å…·
            retrieval_tool = FairCompetitionRetrievalTool()
            tools.append(retrieval_tool)
            
            # æ–‡æ¡£åˆ†æå·¥å…·
            analysis_tool = DocumentAnalysisTool()
            tools.append(analysis_tool)
            
            logger.info(f"å·¥å…·åˆå§‹åŒ–å®Œæˆï¼Œå…± {len(tools)} ä¸ªå·¥å…·")
            return tools
            
        except Exception as e:
            logger.error(f"å·¥å…·åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return []

    def _initialize_memory(self):
        """åˆå§‹åŒ–è®°å¿†"""
        try:
            memory_config = self.settings.get_memory_config()
            
            if memory_config["memory_type"] == "buffer":
                return ConversationBufferMemory(
                    memory_key="chat_history",
                    return_messages=True
                )
            elif memory_config["memory_type"] == "summary":
                return ConversationSummaryMemory(
                    llm=self.llm,
                    memory_key="chat_history",
                    return_messages=True
                )
            elif memory_config["memory_type"] == "window":
                return ConversationBufferWindowMemory(
                    k=memory_config["window_size"],
                    memory_key="chat_history",
                    return_messages=True
                )
            else:
                logger.warning(f"ä¸æ”¯æŒçš„è®°å¿†ç±»å‹: {memory_config['memory_type']}ï¼Œä½¿ç”¨é»˜è®¤buffer")
                return ConversationBufferMemory(
                    memory_key="chat_history",
                    return_messages=True
                )
                
        except Exception as e:
            logger.error(f"è®°å¿†åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )

    def _create_prompt(self) -> ChatPromptTemplate:
        """åˆ›å»ºæç¤ºè¯æ¨¡æ¿"""
        try:
            system_message = """ä½ æ˜¯å…¬å¹³ç«äº‰å®¡æŸ¥é¢†åŸŸçš„ä¸“ä¸šAIåŠ©æ‰‹ã€‚ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š

1. ä¸“ä¸šçŸ¥è¯†ï¼šæ·±åº¦ç†è§£å…¬å¹³ç«äº‰å®¡æŸ¥ç›¸å…³æ³•å¾‹æ³•è§„
2. æ£€ç´¢èƒ½åŠ›ï¼šèƒ½å¤Ÿä»æ”¿ç­–æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯
3. åˆ†æèƒ½åŠ›ï¼šèƒ½å¤Ÿåˆ†ææ”¿ç­–åˆè§„æ€§å’Œé£é™©ç‚¹
4. è®°å¿†èƒ½åŠ›ï¼šèƒ½å¤Ÿè®°ä½å¯¹è¯å†å²ï¼Œæä¾›è¿è´¯çš„å›ç­”

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä½¿ç”¨åˆé€‚çš„å·¥å…·æ¥è·å–ä¿¡æ¯ï¼Œå¹¶æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”ã€‚
å¦‚æœé—®é¢˜æ¶‰åŠå…¬å¹³ç«äº‰å®¡æŸ¥ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨æ£€ç´¢å·¥å…·è·å–ç›¸å…³æ”¿ç­–ä¿¡æ¯ã€‚"""

            prompt = ChatPromptTemplate.from_messages([
                ("system", system_message),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])
            
            logger.info("æç¤ºè¯æ¨¡æ¿åˆ›å»ºæˆåŠŸ")
            return prompt
            
        except Exception as e:
            logger.error(f"æç¤ºè¯æ¨¡æ¿åˆ›å»ºå¤±è´¥: {str(e)}")
            raise ValueError(f"æç¤ºè¯æ¨¡æ¿åˆ›å»ºå¤±è´¥: {str(e)}")

    def _create_agent(self):
        """åˆ›å»ºAgent"""
        try:
            agent = create_openai_tools_agent(
                llm=self.llm,
                tools=self.tools,
                prompt=self.prompt
            )
            
            logger.info("Agentåˆ›å»ºæˆåŠŸ")
            return agent
            
        except Exception as e:
            logger.error(f"Agentåˆ›å»ºå¤±è´¥: {str(e)}")
            raise ValueError(f"Agentåˆ›å»ºå¤±è´¥: {str(e)}")

    def _create_agent_executor(self) -> AgentExecutor:
        """åˆ›å»ºAgentæ‰§è¡Œå™¨"""
        try:
            executor = AgentExecutor(
                agent=self.agent,
                tools=self.tools,
                memory=self.memory,
                verbose=getattr(self.config, "verbose", True),
                max_iterations=getattr(self.config, "max_iterations", 5),
                handle_parsing_errors=True,
                return_intermediate_steps=True
            )
            
            logger.info("Agentæ‰§è¡Œå™¨åˆ›å»ºæˆåŠŸ")
            return executor
            
        except Exception as e:
            logger.error(f"Agentæ‰§è¡Œå™¨åˆ›å»ºå¤±è´¥: {str(e)}")
            raise ValueError(f"Agentæ‰§è¡Œå™¨åˆ›å»ºå¤±è´¥: {str(e)}")

    def chat(self, user_input: str) -> str:
        """ä¸Agentå¯¹è¯"""
        try:
            if not user_input.strip():
                return "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜"
            
            # æ‰§è¡ŒAgent
            result = self.agent_executor.invoke({
                "input": user_input
            })
            
            # æå–å›ç­”
            response = result.get("output", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")
            
            logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input[:50]}...")
            logger.info(f"Agentå›ç­”: {response[:50]}...")
            
            return response
            
        except Exception as e:
            logger.error(f"å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}")
            return f"å¤„ç†å¤±è´¥: {str(e)}"

    def chat_stream(self, user_input: str):
        """ä¸Agentå¯¹è¯ - æµå¼è¾“å‡º"""
        import time
        import sys
        
        try:
            if not user_input.strip():
                yield "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜"
                return
            
            logger.info(f"å¼€å§‹æµå¼å¯¹è¯: {user_input[:50]}...")
            
            # æµå¼æ‰§è¡ŒAgent
            full_response = ""
            for chunk in self.agent_executor.stream({
                "input": user_input
            }):
                if "output" in chunk:
                    # è¾“å‡ºå†…å®¹
                    content = chunk["output"]
                    if content:
                        # é€å­—ç¬¦è¾“å‡ºï¼Œæ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ
                        for char in content:
                            full_response += char
                            yield char
                            time.sleep(0.02)  # æ§åˆ¶è¾“å‡ºé€Ÿåº¦
                        yield "\n"  # æ¢è¡Œ
                        
                elif "actions" in chunk:
                    # å·¥å…·è°ƒç”¨ä¿¡æ¯
                    actions = chunk["actions"]
                    for action in actions:
                        if hasattr(action, 'tool') and hasattr(action, 'tool_input'):
                            tool_msg = f"\nğŸ”§ æ­£åœ¨ä½¿ç”¨å·¥å…·: {action.tool}\n"
                            for char in tool_msg:
                                yield char
                                time.sleep(0.01)
                                
                elif "steps" in chunk:
                    # ä¸­é—´æ­¥éª¤
                    steps = chunk["steps"]
                    for step in steps:
                        if hasattr(step, 'observation'):
                            step_msg = f"\nğŸ“‹ å·¥å…·ç»“æœ: {step.observation[:100]}...\n"
                            for char in step_msg:
                                yield char
                                time.sleep(0.01)
            
        except Exception as e:
            logger.error(f"æµå¼å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}")
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            for char in error_msg:
                yield char
                time.sleep(0.02)

    def chat_stream_advanced(self, user_input: str):
        """é«˜çº§æµå¼è¾“å‡º - ç›´æ¥ä½¿ç”¨LLMæµå¼å“åº”"""
        import time
        import asyncio
        from langchain.schema import HumanMessage
        
        try:
            if not user_input.strip():
                yield "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜"
                return
            
            logger.info(f"å¼€å§‹é«˜çº§æµå¼å¯¹è¯: {user_input[:50]}...")
            
            # æ„å»ºæ¶ˆæ¯
            messages = [HumanMessage(content=user_input)]
            
            # å¦‚æœæœ‰è®°å¿†ï¼Œæ·»åŠ å†å²æ¶ˆæ¯
            if hasattr(self.memory, 'chat_memory') and self.memory.chat_memory.messages:
                messages = self.memory.chat_memory.messages + messages
            
            # ç›´æ¥ä½¿ç”¨LLMçš„æµå¼å“åº”
            response_text = ""
            for chunk in self.llm.stream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    content = chunk.content
                    response_text += content
                    
                    # é€å­—ç¬¦è¾“å‡º
                    for char in content:
                        yield char
                        time.sleep(0.03)  # ç¨å¾®æ…¢ä¸€ç‚¹ï¼Œæ›´çœŸå®
            
            # ä¿å­˜åˆ°è®°å¿†
            if hasattr(self.memory, 'chat_memory'):
                self.memory.chat_memory.add_user_message(user_input)
                self.memory.chat_memory.add_ai_message(response_text)
            
            logger.info(f"æµå¼å¯¹è¯å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response_text)}")
            
        except Exception as e:
            logger.error(f"é«˜çº§æµå¼å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}")
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            for char in error_msg:
                yield char
                time.sleep(0.02)

    def get_memory_status(self) -> Dict[str, Any]:
        """è·å–è®°å¿†çŠ¶æ€"""
        try:
            if hasattr(self.memory, 'chat_memory'):
                messages = self.memory.chat_memory.messages
                return {
                    "memory_type": "buffer",
                    "message_count": len(messages),
                    "recent_messages": [
                        {
                            "type": type(msg).__name__,
                            "content": msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
                        }
                        for msg in messages[-5:]  # æœ€è¿‘5æ¡æ¶ˆæ¯
                    ]
                }
            else:
                return {
                    "memory_type": "buffer",
                    "message_count": 0,
                    "recent_messages": []
                }
        except Exception as e:
            logger.error(f"è·å–è®°å¿†çŠ¶æ€å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    def clear_memory(self) -> bool:
        """æ¸…ç©ºè®°å¿†"""
        try:
            if hasattr(self.memory, 'clear'):
                self.memory.clear()
                logger.info("è®°å¿†å·²æ¸…ç©º")
                return True
            else:
                logger.warning("å½“å‰è®°å¿†ç±»å‹ä¸æ”¯æŒæ¸…ç©ºæ“ä½œ")
                return False
        except Exception as e:
            logger.error(f"æ¸…ç©ºè®°å¿†å¤±è´¥: {str(e)}")
            return False

    def get_agent_status(self) -> Dict[str, Any]:
        """è·å–AgentçŠ¶æ€"""
        try:
            return {
                "name": getattr(self.config, "name", "FairCompetitionAgent"),
                "llm_provider": "volcengine_ark",
                "llm_model": "doubao-seed-1-6-250615",
                "tools_count": len(self.tools),
                "memory_type": "buffer",
                "max_iterations": getattr(self.config, "max_iterations", 5),
                "verbose": getattr(self.config, "verbose", True)
            }
        except Exception as e:
            logger.error(f"è·å–AgentçŠ¶æ€å¤±è´¥: {str(e)}")
            return {"error": str(e)}


class LangChainAgentManager:
    """LangChain Agentç®¡ç†å™¨"""
    
    def __init__(self):
        self.agents: Dict[str, LangChainAgent] = {}
        self.settings = get_settings()
    
    def create_agent(self, name: str, config: Optional[Dict[str, Any]] = None) -> LangChainAgent:
        """åˆ›å»ºAgent"""
        try:
            agent = LangChainAgent(config)
            self.agents[name] = agent
            logger.info(f"Agent '{name}' åˆ›å»ºæˆåŠŸ")
            return agent
        except Exception as e:
            logger.error(f"åˆ›å»ºAgent '{name}' å¤±è´¥: {str(e)}")
            raise
    
    def get_agent(self, name: str) -> Optional[LangChainAgent]:
        """è·å–Agent"""
        return self.agents.get(name)
    
    def list_agents(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰Agent"""
        return list(self.agents.keys())
    
    def delete_agent(self, name: str) -> bool:
        """åˆ é™¤Agent"""
        if name in self.agents:
            del self.agents[name]
            logger.info(f"Agent '{name}' å·²åˆ é™¤")
            return True
        return False
    
    def chat_with_agent(self, agent_name: str, user_input: str) -> str:
        """ä¸æŒ‡å®šAgentå¯¹è¯"""
        agent = self.get_agent(agent_name)
        if not agent:
            return f"Agent '{agent_name}' ä¸å­˜åœ¨"
        
        return agent.chat(user_input)


def create_langchain_agent(config: Optional[Dict[str, Any]] = None) -> LangChainAgent:
    """åˆ›å»ºLangChain Agent"""
    return LangChainAgent(config)


def create_agent_manager() -> LangChainAgentManager:
    """åˆ›å»ºAgentç®¡ç†å™¨"""
    return LangChainAgentManager()


if __name__ == "__main__":
    # æµ‹è¯•Agent
    print("=== LangChain Agentæµ‹è¯• ===")
    
    try:
        # åˆ›å»ºAgent
        agent = create_langchain_agent()
        
        # æµ‹è¯•çŠ¶æ€
        status = agent.get_agent_status()
        print(f"AgentçŠ¶æ€: {status}")
        
        # æµ‹è¯•å¯¹è¯
        response = agent.chat("ä½ å¥½ï¼Œä½ èƒ½å¸®æˆ‘åšä»€ä¹ˆï¼Ÿ")
        print(f"Agentå›ç­”: {response}")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {str(e)}")

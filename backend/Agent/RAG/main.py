import logging

from RAG.classifiers.bert_classifier import BertSentenceClassifier
from RAG.retrieval.vectorstore import build_vector_index
from RAG.retrieval.bm25 import build_bm25_retriever
from RAG.retrieval.hybrid import hybrid_retrieval
from RAG.utils.llm_intent import intent_translate, simple_llm_call
from RAG.io_utils.inputs import get_single_sentence_input
from RAG.pipeline.analysis import parallel_process_document, save_violation_results
from RAG.config.constants import (
    EMBEDDING_MODEL,
    STRUCTURED_CHUNKS_JSON_PATH,
    input_path,
    VIOLATION_OUTPUT_DIR,
)
from RAG.doc_utils.JsonLoader import load_structured_chunks_from_json, load_and_process_documents

logger = logging.getLogger(__name__)


def run():
    FORCE_RECREATE_VECTOR_INDEX = True

    logger.info("=" * 60)
    logger.info("å…¬å¹³ç«äº‰å®¡æŸ¥å…¨æµç¨‹ï¼ˆçº¯æ–‡æœ¬è¾“å…¥+å¹¶è¡Œåˆ†æ+ç»“æœä¿å­˜ï¼‰")
    logger.info("=" * 60)

    logger.info("[1/6] åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
    test_response = simple_llm_call("æµ‹è¯•è¿æ¥ï¼šè¿”å›'LLM_OK'")
    if "LLM_OK" not in test_response:
        logger.warning("âš ï¸ LLMè¿æ¥æµ‹è¯•å¼‚å¸¸ï¼Œå¯èƒ½å½±å“åç»­åˆ†æ")
    else:
        logger.info("âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")



    logger.info("[2/6] åˆå§‹åŒ–BERTåˆ†ç±»å™¨...")

    bert_classifier = BertSentenceClassifier()

    logger.info("[3/6] åŠ è½½æ£€ç´¢åº“æ–‡æ¡£åˆ†å—...")


    try:
        doc_chunks = load_structured_chunks_from_json(STRUCTURED_CHUNKS_JSON_PATH)
    except (FileNotFoundError, ValueError) as e:
        logger.warning(f"âš ï¸ ä»JSONåŠ è½½å¤±è´¥ï¼š{str(e)}ï¼Œå°†é‡æ–°å¤„ç†æœ¬åœ°æ–‡æ¡£")
        doc_chunks = load_and_process_documents(input_dir=input_path, save_json_path=STRUCTURED_CHUNKS_JSON_PATH)
        FORCE_RECREATE_VECTOR_INDEX = True

    if not doc_chunks:
        logger.error("âŒ æ— æœ‰æ•ˆæ–‡æ¡£åˆ†å—ï¼Œç¨‹åºç»ˆæ­¢")
        return
    logger.info(f"âœ… åŠ è½½æ–‡æ¡£åˆ†å— {len(doc_chunks)} ä¸ª")

    logger.info("[4/6] æ„å»ºæ£€ç´¢ç»„ä»¶...")

    logger.info(f"ğŸ”§ ä½¿ç”¨embeddingæ¨¡å‹ï¼š{EMBEDDING_MODEL}ï¼Œå¼ºåˆ¶é‡å»ºï¼š{FORCE_RECREATE_VECTOR_INDEX}")

    vectordb = build_vector_index(doc_chunks, force_recreate=FORCE_RECREATE_VECTOR_INDEX)

    bm25_retriever = build_bm25_retriever(doc_chunks)

    logger.info("âœ… æ£€ç´¢ç»„ä»¶ï¼ˆFAISS+BM25ï¼‰æ„å»ºå®Œæˆ")

    text = "å‚ä¸è¯„ä¼˜è¯„å¥–ä¼ä¸šéœ€è¦åœ¨æœ¬åœ°è½æˆ·"
    logger.info("[5/6] æ¥æ”¶ç”¨æˆ·è¾“å…¥å¹¶æ‰§è¡Œå¹¶è¡Œåˆ†æ...")
    user_input_chunks = get_single_sentence_input(text)
    user_text = user_input_chunks[0]["page_content"]

    intent_dict = intent_translate(user_text)
    retrieval_query = intent_dict.get("normalized_query", user_text) or user_text

    logger.info(f"ğŸ” æ‰§è¡Œæ£€ç´¢ï¼ˆæ£€ç´¢æŒ‡ä»¤ï¼š{retrieval_query}ï¼‰")
    retrieval_results = hybrid_retrieval(
        vectordb=vectordb,
        bm25_retriever=bm25_retriever,
        query=retrieval_query,
        intent_dict=intent_dict,
    )
    logger.info("\n" + "=" * 80)
    logger.info(f"ğŸ“Œ æ£€ç´¢ç»“æœå‚è€ƒï¼ˆç”¨æˆ·è¾“å…¥ï¼š{user_text[:50]}...ï¼‰")
    logger.info("=" * 80)
    for i, (score, doc) in enumerate(retrieval_results, 1):
        source = doc.metadata.get("file_name", "æœªçŸ¥æ–‡ä»¶")
        chapter = doc.metadata.get("parent_chapter_title", "æœªçŸ¥ç« èŠ‚")
        content = doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content
        logger.info(f"\nã€ç¬¬{i}æ¡ã€‘- ç›¸ä¼¼åº¦ï¼š{score:.3f}")
        logger.info(f"æ¥æºï¼š{source} > {chapter}")
        logger.info(f"å†…å®¹ï¼š{content}")
    logger.info("=" * 80 + "\n")

    logger.info("ğŸš€ å¯åŠ¨BERT+LLMå¹¶è¡Œåˆ†æ...")


    violation_results = parallel_process_document(
        document_chunks=user_input_chunks,
        bert_classifier=bert_classifier,
        vectordb=vectordb,
        bm25_retriever=bm25_retriever,
    )

    if violation_results:
        save_violation_results(violation_results)
        logger.info(f"ğŸ‰ å…¨æµç¨‹å®Œæˆï¼å…±å‘ç° {len(violation_results)} æ¡ç»“æœï¼Œå·²ä¿å­˜è‡³ {VIOLATION_OUTPUT_DIR}")
    else:
        logger.info("ğŸ‰ å…¨æµç¨‹å®Œæˆï¼æœªå‘ç°è¿è§„ç»“æœ")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
    run()

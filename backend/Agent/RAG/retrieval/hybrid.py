import logging
from typing import List, Tuple, Dict

from langchain.schema import Document
from langchain_community.vectorstores import FAISS as LangChainFAISS

logger = logging.getLogger(__name__)


def hybrid_retrieval(
    vectordb: LangChainFAISS,
    bm25_retriever,
    query: str,
    intent_dict: dict,
    candidate_size: int = 20,
    final_k: int = 10,
    vector_weight: float = 0.5,
    bm25_weight: float = 0.5,
) -> List[Tuple[float, Document]]:
    candidate_docs: Dict[int, Dict] = {}

    try:
        vector_results = vectordb.similarity_search_with_score(query, k=candidate_size)
        for doc, distance in vector_results:
            similarity_score = 1.0 / (1.0 + distance)
            doc_id = hash(doc.page_content)
            candidate_docs[doc_id] = {"doc": doc, "vector_score": similarity_score, "bm25_score": 0}
        logger.debug(f"âœ… FAISSæ£€ç´¢åˆ° {len(vector_results)} æ¡å€™é€‰ç»“æœ")
    except Exception as e:
        logger.error(f"âŒ FAISSæ£€ç´¢å¤±è´¥ï¼š{str(e)}", exc_info=True)

    try:
        need_chapter_filter = intent_dict.get("need_chapter_filter") == "æ˜¯"
        target_chapters = intent_dict.get("target_chapters", [])

        # Prefer using keywords from intent translation for BM25 if provided
        bm25_query = query
        try:
            keywords = intent_dict.get("keywords")
            if isinstance(keywords, list) and len(keywords) > 0:
                bm25_query = " ".join([str(k) for k in keywords if str(k).strip()])
                logger.debug(f"ğŸ” ä½¿ç”¨intent keywordsä½œä¸ºBM25æŸ¥è¯¢ï¼š{bm25_query}")
        except Exception as kw_e:
            logger.warning(f"âš ï¸ è§£æintent keywordså¤±è´¥ï¼Œå›é€€ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼š{str(kw_e)}")

        if need_chapter_filter and target_chapters:
            bm25_results = bm25_retriever.retrieve_with_chapter_filter(
                query=bm25_query, target_chapters=target_chapters, top_k=candidate_size
            )
        else:
            bm25_results = bm25_retriever.retrieve(query=bm25_query, top_k=candidate_size)

        for score, doc in bm25_results:
            doc_id = hash(doc.page_content)
            if doc_id in candidate_docs:
                candidate_docs[doc_id]["bm25_score"] = score
            else:
                if score > 0:
                    candidate_docs[doc_id] = {"doc": doc, "vector_score": 0, "bm25_score": score}
        logger.debug(f"âœ… BM25æ£€ç´¢åˆ° {len(bm25_results)} æ¡å€™é€‰ç»“æœ")
    except Exception as e:
        logger.error(f"âŒ BM25æ£€ç´¢å¤±è´¥ï¼š{str(e)}", exc_info=True)

    if not candidate_docs:
        logger.warning("âŒ æ··åˆæ£€ç´¢æ— å€™é€‰ç»“æœ")
        return []

    max_vector = max([d["vector_score"] for d in candidate_docs.values()], default=1)
    max_bm25 = max([d["bm25_score"] for d in candidate_docs.values()], default=1)

    reranked: List[Tuple[float, Document]] = []
    for doc_item in candidate_docs.values():
        norm_vector = doc_item["vector_score"] / max_vector if max_vector != 0 else 0
        norm_bm25 = doc_item["bm25_score"] / max_bm25 if max_bm25 != 0 else 0
        combined_score = (norm_vector * vector_weight) + (norm_bm25 * bm25_weight)
        reranked.append((combined_score, doc_item["doc"]))

    reranked.sort(key=lambda x: x[0], reverse=True)
    final_results = reranked[:final_k]
    logger.info(f"âœ… æ··åˆæ£€ç´¢å®Œæˆï¼Œè¿”å›Top {len(final_results)} ç»“æœ")
    return final_results
